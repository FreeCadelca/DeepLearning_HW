{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_upCOEI3Upu"
   },
   "source": [
    "# Основы глубинного обучения, майнор ИАД\n",
    "\n",
    "## Домашнее задание 1: полносвязные сети\n",
    "\n",
    "**ФИО:**\n",
    "\n",
    "**Факт о себе:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общая информация\n",
    "\n",
    "__Дата выдачи:__ 22.09.2025\n",
    "\n",
    "__Мягкий дедлайн:__ 23:59MSK 12.10.2025\n",
    "\n",
    "__Жесткий дедлайн:__ 23:59MSK 19.10.2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Оценивание и штрафы\n",
    "\n",
    "Максимально допустимая оценка за работу — 10 баллов. Сдавать задание после указанного срока сдачи нельзя.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).  Если два студента сгенерировали в нейронке одинаковые либо похожие решения, это считается плагиатом и приводит к обнулению обеих работ.\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
    "\n",
    "Итогова оценка считается как\n",
    "\n",
    "$$\n",
    "min(part_1, part_2) \\cdot 0.6 + max(part_1, part_2) \\cdot 0.2 + part_3 \\cdot 0.2\n",
    "$$\n",
    "\n",
    "где $part_1$, $part_2$ и $part_3$ - оценки за первую, вторую и третью части работы\n",
    "\n",
    "> Также, за домашнее задание выставляется 0, если не сделано нулевое задание либо нет подробного описания ваших экспериментов в третьей части."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оформление\n",
    "\n",
    "1. Обязательно фиксируйте зерно генератора случайных чисел в экспериментах. При перезапуске кода значения не должны меняться.\n",
    "2. Вверху файла подпишите фамилию, имя и какой-то занимательный факт о себе.\n",
    "3. Обратите внимание, что у графиков должны быть подписаны оси, заголовок графика и при необходимости обязательно наличие легенды. \n",
    "\n",
    "> За отсутствие названий графиков и подписей к осям могут снижаться баллы. Все картинки должны быть самодостаточны и визуально удобны для восприятия, так чтобы не нужно было смотреть ваш код или знать задание, чтобы понять что на них изображено.\n",
    "\n",
    "Из каждого проведённого эксперимента делайте выводы и фиксируйте их. Эти выводы не должны быть поверхностными и очевидными. Не будьте мудрым королём.\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/hse-ds/iad-deep-learning/refs/heads/master/2025/homeworks/king.png\" width=\"300\"> \n",
    "</center>\n",
    "\n",
    "**Пример плохого вывода:** Синенькая линия идет вверх, а красная вниз. Черненькая идет вниз, а потом вверх. \n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/hse-ds/iad-deep-learning/refs/heads/master/2025/homeworks/bad_lines.png\" width=\"600\"> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## О задании\n",
    "\n",
    "Вам предстоит обучить полносвязную нейронную сеть для предсказания года выпуска песни по ее аудио-признакам. Для этого мы будем использовать [Million Songs Dataset](https://samyzaf.com/ML/song_year/song_year.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RI_eoe063VaP",
    "ExecuteTime": {
     "end_time": "2025-10-09T15:00:53.083558200Z",
     "start_time": "2025-10-09T15:00:47.574635100Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с того, что скачаем и загрузим данные: (У меня винда + PyCharm со своей видеокартой, поэтому wget мне не подойдет, я переписал код)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NgSZeU-7vgj",
    "outputId": "4d53550a-d654-4efd-ddc8-e580328bab80",
    "ExecuteTime": {
     "end_time": "2025-10-09T15:00:53.088202Z",
     "start_time": "2025-10-09T15:00:53.083558200Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget -O yearpredictionmsd.zip https://archive.ics.uci.edu/static/public/203/yearpredictionmsd.zip\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"yearpredictionmsd.zip\"):\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://archive.ics.uci.edu/static/public/203/yearpredictionmsd.zip\", \n",
    "        \"yearpredictionmsd.zip\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "DSVJZzkJ7zZE",
    "outputId": "2c5b9ac3-1194-4c3e-be92-067640e01e3a",
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2025-10-09T15:00:59.477387Z",
     "start_time": "2025-10-09T15:00:53.088202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     0         1         2         3         4         5         6         7   \\\n0  2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905 -25.01202   \n1  2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   8.76630   \n2  2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940  -3.27872   \n3  2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   5.05097   \n4  2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409 -12.48207   \n\n         8         9   ...        81         82        83        84        85  \\\n0 -12.23257   7.83089  ...  13.01620  -54.40548  58.99367  15.37344   1.11144   \n1  -0.92019  18.76548  ...   5.66812  -19.68073  33.04964  42.87836  -9.90378   \n2  -2.35035  16.07017  ...   3.03800   26.05866 -50.92779  10.93792  -0.07568   \n3 -10.34124   3.55005  ...  34.57337 -171.70734 -16.96705 -46.67617 -12.51516   \n4  -9.37636  12.63699  ...   9.92661  -55.95724  64.92712 -17.72522  -1.49237   \n\n         86         87        88         89        90  \n0 -23.08793   68.40795  -1.82223  -27.46348   2.26327  \n1 -32.22788   70.49388  12.04941   58.43453  26.92061  \n2  43.20130 -115.00698  -0.05859   39.67068  -0.66345  \n3  82.58061  -72.08993   9.90558  199.62971  18.85382  \n4  -7.50035   51.76631   7.88713   55.66926  28.74903  \n\n[5 rows x 91 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>81</th>\n      <th>82</th>\n      <th>83</th>\n      <th>84</th>\n      <th>85</th>\n      <th>86</th>\n      <th>87</th>\n      <th>88</th>\n      <th>89</th>\n      <th>90</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2001</td>\n      <td>49.94357</td>\n      <td>21.47114</td>\n      <td>73.07750</td>\n      <td>8.74861</td>\n      <td>-17.40628</td>\n      <td>-13.09905</td>\n      <td>-25.01202</td>\n      <td>-12.23257</td>\n      <td>7.83089</td>\n      <td>...</td>\n      <td>13.01620</td>\n      <td>-54.40548</td>\n      <td>58.99367</td>\n      <td>15.37344</td>\n      <td>1.11144</td>\n      <td>-23.08793</td>\n      <td>68.40795</td>\n      <td>-1.82223</td>\n      <td>-27.46348</td>\n      <td>2.26327</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2001</td>\n      <td>48.73215</td>\n      <td>18.42930</td>\n      <td>70.32679</td>\n      <td>12.94636</td>\n      <td>-10.32437</td>\n      <td>-24.83777</td>\n      <td>8.76630</td>\n      <td>-0.92019</td>\n      <td>18.76548</td>\n      <td>...</td>\n      <td>5.66812</td>\n      <td>-19.68073</td>\n      <td>33.04964</td>\n      <td>42.87836</td>\n      <td>-9.90378</td>\n      <td>-32.22788</td>\n      <td>70.49388</td>\n      <td>12.04941</td>\n      <td>58.43453</td>\n      <td>26.92061</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2001</td>\n      <td>50.95714</td>\n      <td>31.85602</td>\n      <td>55.81851</td>\n      <td>13.41693</td>\n      <td>-6.57898</td>\n      <td>-18.54940</td>\n      <td>-3.27872</td>\n      <td>-2.35035</td>\n      <td>16.07017</td>\n      <td>...</td>\n      <td>3.03800</td>\n      <td>26.05866</td>\n      <td>-50.92779</td>\n      <td>10.93792</td>\n      <td>-0.07568</td>\n      <td>43.20130</td>\n      <td>-115.00698</td>\n      <td>-0.05859</td>\n      <td>39.67068</td>\n      <td>-0.66345</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2001</td>\n      <td>48.24750</td>\n      <td>-1.89837</td>\n      <td>36.29772</td>\n      <td>2.58776</td>\n      <td>0.97170</td>\n      <td>-26.21683</td>\n      <td>5.05097</td>\n      <td>-10.34124</td>\n      <td>3.55005</td>\n      <td>...</td>\n      <td>34.57337</td>\n      <td>-171.70734</td>\n      <td>-16.96705</td>\n      <td>-46.67617</td>\n      <td>-12.51516</td>\n      <td>82.58061</td>\n      <td>-72.08993</td>\n      <td>9.90558</td>\n      <td>199.62971</td>\n      <td>18.85382</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2001</td>\n      <td>50.97020</td>\n      <td>42.20998</td>\n      <td>67.09964</td>\n      <td>8.46791</td>\n      <td>-15.85279</td>\n      <td>-16.81409</td>\n      <td>-12.48207</td>\n      <td>-9.37636</td>\n      <td>12.63699</td>\n      <td>...</td>\n      <td>9.92661</td>\n      <td>-55.95724</td>\n      <td>64.92712</td>\n      <td>-17.72522</td>\n      <td>-1.49237</td>\n      <td>-7.50035</td>\n      <td>51.76631</td>\n      <td>7.88713</td>\n      <td>55.66926</td>\n      <td>28.74903</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 91 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('yearpredictionmsd.zip', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на статистики по данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:01:01.263901500Z",
     "start_time": "2025-10-09T15:00:59.445043200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  0              1              2              3   \\\ncount  515345.000000  515345.000000  515345.000000  515345.000000   \nmean     1998.397082      43.387126       1.289554       8.658347   \nstd        10.931046       6.067558      51.580351      35.268585   \nmin      1922.000000       1.749000    -337.092500    -301.005060   \n25%      1994.000000      39.954690     -26.059520     -11.462710   \n50%      2002.000000      44.258500       8.417850      10.476320   \n75%      2006.000000      47.833890      36.124010      29.764820   \nmax      2011.000000      61.970140     384.065730     322.851430   \n\n                  4              5              6              7   \\\ncount  515345.000000  515345.000000  515345.000000  515345.000000   \nmean        1.164124      -6.553601      -9.521975      -2.391089   \nstd        16.322790      22.860785      12.857751      14.571873   \nmin      -154.183580    -181.953370     -81.794290    -188.214000   \n25%        -8.487500     -20.666450     -18.440990     -10.780600   \n50%        -0.652840      -6.007770     -11.188390      -2.046670   \n75%         8.787540       7.741870      -2.388960       6.508580   \nmax       335.771820     262.068870     166.236890     172.402680   \n\n                  8              9   ...             81             82  \\\ncount  515345.000000  515345.000000  ...  515345.000000  515345.000000   \nmean       -1.793236       3.727876  ...      15.755406     -73.461500   \nstd         7.963827      10.582861  ...      32.099635     175.618889   \nmin       -72.503850    -126.479040  ...    -437.722030   -4402.376440   \n25%        -6.468420      -2.293660  ...      -1.812650    -139.555160   \n50%        -1.736450       3.822310  ...       9.171850     -53.090060   \n75%         2.913450       9.961820  ...      26.274480      13.478730   \nmax       126.741270     146.297950  ...     840.973380    4469.454870   \n\n                  83             84             85             86  \\\ncount  515345.000000  515345.000000  515345.000000  515345.000000   \nmean       41.542422      37.934119       0.315751      17.669213   \nstd       122.228799      95.050631      16.161764     114.427905   \nmin     -1810.689190   -3098.350310    -341.789120   -3168.924570   \n25%       -20.986900      -4.669540      -6.781590     -31.580610   \n50%        28.791060      33.623630       0.820840      15.598470   \n75%        89.661770      77.785800       8.470990      67.794960   \nmax      3210.701700    1734.079690     260.544900    3662.065650   \n\n                  87             88             89             90  \ncount  515345.000000  515345.000000  515345.000000  515345.000000  \nmean      -26.315336       4.458641      20.035136       1.329105  \nstd       173.977336      13.346557     185.558247      22.088576  \nmin     -4319.992320    -236.039260   -7458.378150    -381.424430  \n25%      -101.530300      -2.566090     -59.509270      -8.820210  \n50%       -21.204120       3.117640       7.759730       0.053050  \n75%        52.389330       9.967740      86.351610       9.679520  \nmax      2833.608950     463.419500    7393.398440     677.899630  \n\n[8 rows x 91 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>81</th>\n      <th>82</th>\n      <th>83</th>\n      <th>84</th>\n      <th>85</th>\n      <th>86</th>\n      <th>87</th>\n      <th>88</th>\n      <th>89</th>\n      <th>90</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>...</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n      <td>515345.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1998.397082</td>\n      <td>43.387126</td>\n      <td>1.289554</td>\n      <td>8.658347</td>\n      <td>1.164124</td>\n      <td>-6.553601</td>\n      <td>-9.521975</td>\n      <td>-2.391089</td>\n      <td>-1.793236</td>\n      <td>3.727876</td>\n      <td>...</td>\n      <td>15.755406</td>\n      <td>-73.461500</td>\n      <td>41.542422</td>\n      <td>37.934119</td>\n      <td>0.315751</td>\n      <td>17.669213</td>\n      <td>-26.315336</td>\n      <td>4.458641</td>\n      <td>20.035136</td>\n      <td>1.329105</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>10.931046</td>\n      <td>6.067558</td>\n      <td>51.580351</td>\n      <td>35.268585</td>\n      <td>16.322790</td>\n      <td>22.860785</td>\n      <td>12.857751</td>\n      <td>14.571873</td>\n      <td>7.963827</td>\n      <td>10.582861</td>\n      <td>...</td>\n      <td>32.099635</td>\n      <td>175.618889</td>\n      <td>122.228799</td>\n      <td>95.050631</td>\n      <td>16.161764</td>\n      <td>114.427905</td>\n      <td>173.977336</td>\n      <td>13.346557</td>\n      <td>185.558247</td>\n      <td>22.088576</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1922.000000</td>\n      <td>1.749000</td>\n      <td>-337.092500</td>\n      <td>-301.005060</td>\n      <td>-154.183580</td>\n      <td>-181.953370</td>\n      <td>-81.794290</td>\n      <td>-188.214000</td>\n      <td>-72.503850</td>\n      <td>-126.479040</td>\n      <td>...</td>\n      <td>-437.722030</td>\n      <td>-4402.376440</td>\n      <td>-1810.689190</td>\n      <td>-3098.350310</td>\n      <td>-341.789120</td>\n      <td>-3168.924570</td>\n      <td>-4319.992320</td>\n      <td>-236.039260</td>\n      <td>-7458.378150</td>\n      <td>-381.424430</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1994.000000</td>\n      <td>39.954690</td>\n      <td>-26.059520</td>\n      <td>-11.462710</td>\n      <td>-8.487500</td>\n      <td>-20.666450</td>\n      <td>-18.440990</td>\n      <td>-10.780600</td>\n      <td>-6.468420</td>\n      <td>-2.293660</td>\n      <td>...</td>\n      <td>-1.812650</td>\n      <td>-139.555160</td>\n      <td>-20.986900</td>\n      <td>-4.669540</td>\n      <td>-6.781590</td>\n      <td>-31.580610</td>\n      <td>-101.530300</td>\n      <td>-2.566090</td>\n      <td>-59.509270</td>\n      <td>-8.820210</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2002.000000</td>\n      <td>44.258500</td>\n      <td>8.417850</td>\n      <td>10.476320</td>\n      <td>-0.652840</td>\n      <td>-6.007770</td>\n      <td>-11.188390</td>\n      <td>-2.046670</td>\n      <td>-1.736450</td>\n      <td>3.822310</td>\n      <td>...</td>\n      <td>9.171850</td>\n      <td>-53.090060</td>\n      <td>28.791060</td>\n      <td>33.623630</td>\n      <td>0.820840</td>\n      <td>15.598470</td>\n      <td>-21.204120</td>\n      <td>3.117640</td>\n      <td>7.759730</td>\n      <td>0.053050</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2006.000000</td>\n      <td>47.833890</td>\n      <td>36.124010</td>\n      <td>29.764820</td>\n      <td>8.787540</td>\n      <td>7.741870</td>\n      <td>-2.388960</td>\n      <td>6.508580</td>\n      <td>2.913450</td>\n      <td>9.961820</td>\n      <td>...</td>\n      <td>26.274480</td>\n      <td>13.478730</td>\n      <td>89.661770</td>\n      <td>77.785800</td>\n      <td>8.470990</td>\n      <td>67.794960</td>\n      <td>52.389330</td>\n      <td>9.967740</td>\n      <td>86.351610</td>\n      <td>9.679520</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2011.000000</td>\n      <td>61.970140</td>\n      <td>384.065730</td>\n      <td>322.851430</td>\n      <td>335.771820</td>\n      <td>262.068870</td>\n      <td>166.236890</td>\n      <td>172.402680</td>\n      <td>126.741270</td>\n      <td>146.297950</td>\n      <td>...</td>\n      <td>840.973380</td>\n      <td>4469.454870</td>\n      <td>3210.701700</td>\n      <td>1734.079690</td>\n      <td>260.544900</td>\n      <td>3662.065650</td>\n      <td>2833.608950</td>\n      <td>463.419500</td>\n      <td>7393.398440</td>\n      <td>677.899630</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 91 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевая переменная, год выпуска песни, записана в первом столбце. Посмотрим на ее распределение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:01:01.382641800Z",
     "start_time": "2025-10-09T15:01:01.263901500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range: 1922 - 2011\n",
      "Unique values: 89\n"
     ]
    }
   ],
   "source": [
    "plt.hist(df.iloc[:, 0], bins=20)\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n",
    "print(f'Range: {df.iloc[:, 0].min()} - {df.iloc[:, 0].max()}')\n",
    "print(f'Unique values: {np.unique(df.iloc[:, 0]).size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9a-eJUG35C3"
   },
   "source": [
    "Разобьем данные на обучение и тест (не меняйте здесь ничего, чтобы сплит был одинаковым у всех)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:01:01.488412Z",
     "start_time": "2025-10-09T15:01:01.382641800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((386508, 90), (128837, 90))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "train_size = int(0.75 * X.shape[0])\n",
    "\n",
    "X_train = X[:train_size, :]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:, :]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные советы:\n",
    "\n",
    "- Если вы сразу реализуете обучение на GPU, то у вас будет больше времени на эксперименты, так как любые вычисления будут работать быстрее. Google Colab предоставляет несколько GPU-часов (обычно около 8-10) в сутки бесплатно.\n",
    "\n",
    "- Если вы чего-то не знаете, не стесняйтесь гуглить. В интернете очень много полезной информации, туториалов и советов по глубинному обучению и `pytorch`. Но не забывайте, что за списанный код без ссылки на источник последует наказание.\n",
    "\n",
    "- Чтобы отладить код, можете обучаться на небольшой части данных или даже на одном батче. Если лосс на обучающей выборке не падает, то что-то точно идет не так.\n",
    "\n",
    "- Пользуйтесь утилитами, которые вам предоставляет `pytorch` (например, `Dataset` и `Dataloader`). Их специально разработали для упрощения разработки пайплайна обучения.\n",
    "\n",
    "- Скорее всего, вы захотите отслеживать прогресс обучения. Для создания прогресс-баров есть удобная библиотека `tqdm`.\n",
    "\n",
    "- Быть может, вы захотите, чтобы графики рисовались прямо во время обучения. Можете воспользоваться функцией [clear_output](http://ipython.org/ipython-doc/dev/api/generated/IPython.display.html#IPython.display.clear_output), чтобы удалять старый график и рисовать новый на его месте.\n",
    "\n",
    "- При желании вы можете логгировать метрики обучения и свои эксперименты в WandB либо любой другой сервис. Не забудьте приложить к тетрадке ссылку на результаты экспериментов либо скришноты графиков с пояснениями, что проверяющий должен на них увидеть.\n",
    "\n",
    "- Финальное значение тестовой метрики для удобства проверки выведите в тетрадке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_386JE_o5gOd"
   },
   "source": [
    "## Задание 0 (0 баллов, но при невыполнении максимальная оценка за всю работу &mdash; 0 баллов)\n",
    "\n",
    "Мы будем использовать RMSE как метрику качества. Прежде чем обучать нейронные сети, нам нужно проверить несколько простых бейзлайнов, чтобы было с чем сравнить более сложные алгоритмы. Для этого обучите `Ridge` регрессию из `sklearn`. Кроме того, посчитайте качество при наилучшем константном прогнозе.\n",
    "\n",
    "Для выполнения данного задания (и всех последующих) предобработайте данные.\n",
    "\n",
    "1. Зафиксируйте random_seed везде где только возможно. Вам предоставлена функция для этого, однако вы можете дополнить ее своими дополнениями.\n",
    "2. Обучите `StandertScaler` и предобработайте ваши данные. В следующих заданиях можете использовать другой `scaler` или вообще отказаться от него.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lkfkXylb8U-O",
    "ExecuteTime": {
     "end_time": "2025-10-09T15:01:01.488412Z",
     "start_time": "2025-10-09T15:01:01.478099500Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_global_seed(seed: int) -> None:\n",
    "    \"\"\"Set global seed for reproducibility.\n",
    "    :param int seed: Seed to be set\n",
    "    \"\"\"\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # также можно зафиксировать seed для Dataloader\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    return g\n",
    "\n",
    "# Сид для каждого worker в Dataloader\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = set_global_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GKVVatBw8cH7",
    "ExecuteTime": {
     "end_time": "2025-10-09T15:25:08.334135700Z",
     "start_time": "2025-10-09T15:25:05.773321100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best RMSE у Ridge: 9.473629925446899, lambda = 0.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "best_rmse = 1000\n",
    "best_lambda = 0\n",
    "reg_lambdas = [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]\n",
    "for reg_lambda in reg_lambdas:\n",
    "    model = Ridge(alpha=reg_lambda)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    rmse_for_model = root_mean_squared_error(y_test, y_pred)\n",
    "    if rmse_for_model < best_rmse:\n",
    "        best_rmse = rmse_for_model\n",
    "        best_lambda = reg_lambda\n",
    "\n",
    "print(f\"best RMSE у Ridge: {best_rmse}, lambda = {best_lambda}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([1993.0673493 , 1990.08139497, 1991.08330555, ..., 1996.97099771,\n       2001.89952064, 1999.59960125], shape=(128837,))"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Просто для себя, посмотреть че там лежит в ответах\n",
    "\n",
    "model = Ridge(alpha=0.01)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-09T15:25:09.994498Z",
     "start_time": "2025-10-09T15:25:09.724874500Z"
    }
   },
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJKGuhFi35C4"
   },
   "source": [
    "Лучшая константа для RMSE это среднее. Используйте среднее, расчитанное на трэйне в качестве прогноза для теста и посчитайте для такой наивной модели RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "kOcFuy1P35C4",
    "ExecuteTime": {
     "end_time": "2025-10-09T15:25:14.080847Z",
     "start_time": "2025-10-09T15:25:14.054724900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE у Constant: 10.845542969687791, value = 1998.3753660985026\n"
     ]
    }
   ],
   "source": [
    "class ConstantModel:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "    \n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.DataFrame):\n",
    "        self.value = y_train.mean()\n",
    "        \n",
    "    def predict(self, X_test: pd.DataFrame):\n",
    "        return pd.array([self.value] * X_test.shape[0])\n",
    "\n",
    "\n",
    "model = ConstantModel()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "rmse_for_model = root_mean_squared_error(y_test, y_pred)\n",
    "print(f\"RMSE у Constant: {rmse_for_model}, value = {model.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Как мы видим, у нас не сильно отличается наша модель от константной. Значит, и одна, и вторая, не очень умные, не уловили какие-то связи и т.д. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь приступим к экспериментам с нейросетями. Для начала отделим от данных валидацию. Тестовую выборку мы будем использовать только для того, чтобы измерить итоговую метрику качества модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T15:27:11.818593300Z",
     "start_time": "2025-10-09T15:27:11.405095700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((289881, 90), (96627, 90))"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0xE2E4)\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть I. Обучаем линейную регрессию (максимум 10 баллов)\n",
    "\n",
    "**Задание 1 (10 баллов):** Обучите в `pytorch` линейную регрессию. \n",
    "\n",
    "- Создайте модель линейной регрессии, которая будет состоять только из одного `Linear()` слоя.\n",
    "   \n",
    "- Напишите цикл обучения вашей линейной регрессии. В нем реализуйте подсчет функции потерь, сделайте шаг градиентного спуска. Запрещено использовать готовые оптимизаторы и loss-функции из библиотеки `pytorch`. Для подсчета градиента воспользуйтесь методом backward.\n",
    "   \n",
    "- Запустите обучение на 10 эпохах, после каждой проверяйте значение целевой метрики на тестовой выборке.\n",
    "   \n",
    "- Выведите на экран графики метрики и значения функции потерь на тестовой и обучающей выборке.\n",
    "\n",
    "В данном задании нет цели побить какой-то порог по метрике. Ваша задача &mdash; убедиться в том, что ваш рукописный цикл обучения работает. Для ускорения вычислений и обучения модели можете брать только срез данных, а не весь датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (ง •̀_•́)ง"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть II. Заводим нейронную сеть (максимум 10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже нам предстоит реализовать довольно много различных нейросетей и поставить целую серию экспериментов. Чтобы это всё происходило без боли и страданий, нам нужно держать код в удобном виде.\n",
    "\n",
    "При решении заданий вы можете придерживаться любой адекватной струкуры кода, но мы советуем воспользоваться сигнатурами функций, которые приведены ниже. При необходимости вы можете добавить в них любые нужные вам аргументы и любой нужный функционал. Более того, хорошей практикой является не делать эти функции слишком громоздкими и выносить разные хитрые штуки в отдельные функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(model, optimizer, criterion, train_loader):\n",
    "    \"\"\"Одна эпоха обучения\n",
    "    params:\n",
    "        model - torch.nn.Module to be fitted\n",
    "        optimizer - model optimizer\n",
    "        criterion - loss function from torch.nn\n",
    "        train_loader - torch.utils.data.Dataloader with train set\n",
    "    \"\"\"\n",
    "\n",
    "    # your code here  ♪┏(・o･)┛♪\n",
    "\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_epoch(model, criterion, val_loader):\n",
    "    \"\"\"Одна эпоха валидации модели\n",
    "    params:\n",
    "        model - torch.nn.Module to be fitted\n",
    "        criterion - loss function from torch.nn\n",
    "        val_loader - torch.utils.data.Dataloader with test set\n",
    "                      (if you wish to validate during training)\n",
    "    \"\"\"\n",
    "\n",
    "    # your code here   ฅ^•ﻌ•^ฅ \n",
    "\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, data_loader):\n",
    "    \"\"\" Предсказания модели\n",
    "    params:\n",
    "        model - torch.nn.Module to be evaluated on test set\n",
    "        criterion - loss function from torch.nn\n",
    "        data_loader - torch.utils.data.Dataloader with test set\n",
    "    ----------\n",
    "    returns:\n",
    "        predicts - torch.tensor with shape (len(test_loader.dataset), ),\n",
    "                   which contains predictions for test objects\n",
    "    \"\"\"\n",
    "    \n",
    "    # your code here  =^･ω･^=\n",
    "\n",
    "    predicts = torch.ones(len(test_loader.dataset))\n",
    "    return predicts\n",
    "\n",
    "\n",
    "def train(model, optimizer, criterion, train_loader, val_loader, epochs):\n",
    "    \"\"\" Обучение модели\n",
    "    params:\n",
    "        model - torch.nn.Module to be fitted\n",
    "        optimizer - model optimizer\n",
    "        criterion - loss function from torch.nn\n",
    "        train_loader - torch.utils.data.Dataloader with train set\n",
    "        val_loader - torch.utils.data.Dataloader with test set\n",
    "                      (if you wish to validate during training)\n",
    "        epochs - number of training epochs\n",
    "    \"\"\"\n",
    "    \n",
    "    # your code here  ¯\\_(ツ)_/¯\n",
    "\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (2 балла)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить нашу первую нейронную сеть. Здесь целевая переменная дискретная &mdash; это год выпуска песни. Поэтому будем учить сеть на классификацию.\n",
    "\n",
    "- В качестве архитектуры сети возьмите два линейных слоя с активацией ReLU между ними c числом скрытых нейронов, равным 128.\n",
    "- Используйте SGD с `lr=1e-3`.\n",
    "- Возьмите размер мини-батча около 32-64, примерно 3-4 эпох обучения должно быть достаточно.\n",
    "- Также преобразуйте целевую переменную так, чтобы ее значения принимали значения от $0$ до $C-1$, где $C$ &mdash; число классов (лучше передайте преобразованное значение в DataLoader, исходное нам еще пригодится)\n",
    "- В качестве метрики качества мы используем RMSE. При его подсчёте вам нужно заменить предсказанный нейросеткой класс на конкретный год выпуска песни и использовать его как прогноз. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (￣ω￣)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3 (1 балл).** Прокомментируйте ваши наблюдения. Удалось ли побить бейзлайн? Как вы думаете, хорошая ли идея учить классификатор для этой задачи? Почему?\n",
    "\n",
    "**Ответ:** ... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (2 балла).** Теперь попробуем решать задачу как регрессию. Обучите нейронную сеть на MSE.\n",
    "\n",
    "- Используйте такие же гиперпараметры обучения.\n",
    "- Когда передаете целевую переменную в DataLoader, сделайте reshape в (-1, 1).\n",
    "- Если что-то пойдет не так, можете попробовать меньшие значения `lr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ( ⚆ _ ⚆)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5 (1 балл).** Получилось ли у вас стабилизировать обучение? Помогли ли меньшие значения `lr`? Стало ли лучше от замены классификации на регрессию? Как вы думаете, почему так происходит? В качестве подсказки можете посмотреть на распределение целевой переменной и магнитуду значений признаков.\n",
    "\n",
    "**Ответ:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6 (1 балл).** Начнем с того, что попробуем отнормировать целевую переменную. Для этого воспользуемся min-max нормализацией, чтобы целевая переменная принимала значения от 0 до 1. Реализуйте функции `normalize` и `denormalize`, которые, соответственно, нормируют целевую переменную и применяют обратное преобразование. Минимум и максимум оцените по обучающей выборке (то есть эти константы должны быть фиксированными и не зависеть от передаваемой выборки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sample):\n",
    "    \"\"\"\n",
    "    Min-max normalization to convert sample to [0, 1] range\n",
    "    \"\"\"\n",
    "    # your code here ᕦ(ò_óˇ)ᕤ\n",
    "    pass\n",
    "\n",
    "def denormalize(sample):\n",
    "    \"\"\"\n",
    "    Denormalize sample from [0, 1] to initial range\n",
    "    \"\"\"\n",
    "    # your code here ( ⚆ ω ⚆)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7 (1 балл)** Теперь повторите эксперимент из **задания 4**, обучаясь на нормированной целевой переменной. Сделаем также еще одно изменение: добавим сигмоидную активацию после последнего линейного слоя сети. Таким образом мы гарантируем, что нейронная сеть предсказывает числа из промежутка $[0, 1]$. Использование активации - довольно распространенный прием, когда мы хотим получить числа из определенного диапазона значений. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here  ლ(ಠ益ಠლ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 8 (2 балла).** На этот раз попробуем отнормировать не только целевую переменную, но и сами данные, которые подаются сети на вход. Для них будем использовать нормализацию через среднее и стандартное отклонение. Преобразуйте данные и повторите прошлый эксперимент. Скорее всего, имеет смысл увеличить число эпох обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    " # your code here  ( ͡° ͜ʖ ͡°)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы все сделали правильно, то у вас должно было получиться качество, сравнимое с `Ridge` регрессией.\n",
    "\n",
    "**Мораль:** как видите, нам пришлось сделать очень много хитрых телодвижений, чтобы нейронная сеть работала хотя бы так же, как и простая линейная модель. Здесь, конечно, показан совсем экстремальный случай, когда без нормализации данных нейронная сеть просто не учится. Как правило, в реальности завести нейронную сеть из коробки не очень сложно, но вот заставить ее работать на полную &mdash; куда более трудоемкая задача. Написание пайплайнов обучения нейросетевых моделей требует большой аккуратности, а дебаг часто превращается в угадайку. К счастью, очень часто на помощь приходит интуиция, и мы надеемся, что вы сможете выработать ее в течение нашего курса. Начнем с двух советов, которые стоит принять на вооружение:\n",
    "\n",
    "- Обязательно начинаем любые эксперименты с бейзлайнов: без них мы бы не поняли, что нейронная сеть не учится в принципе.\n",
    "- При постановке эксперментов старайтесь делать минимальное количество изменений за раз (в идеале одно!): только так можно понять, какие конкретно изменения влияют на результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть III. Улучшаем нейронную сеть (максимум 10 баллов)\n",
    "\n",
    "Продолжим экспериментировать с нейронной сетью, чтобы добиться еще лучшего качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 9 (1 балл).** Давайте попробуем другие оптимизаторы. Обучите нейросеть с помощью SGD+momentum и Adam. Опишите свои наблюдения и в дальнейших запусках используйте лучший оптимизатор. Для Adam обычно берут learning rate поменьше, в районе $10^{-3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here  ( ཀ ʖ̯ ཀ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 10 (1 балл).** Теперь сделаем нашу нейронную сеть более сложной. Попробуйте сделать сеть:\n",
    "\n",
    "- более широкой (то есть увеличить размерность скрытого слоя, например, вдвое)\n",
    "- более глубокой (то есть добавить еще один скрытый слой)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here  (๑-﹏-๑)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишите, как увеличение числа параметров модели влияет на качество на обучающей и валидационной выборках (без их описания за работу ставится ноль баллов)\n",
    "\n",
    "__Ваше подробное описание:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 11 (1 балл).** Как вы должны были заметить, более сложная модель стала сильнее переобучаться. Попробуем разные методы регуляризации, чтобы бороться с переобучением. Проведите два эксперимента:\n",
    "\n",
    "- Добавьте слой дропаута с параметром $p=0.2$ после каждого линейного слоя, кроме последнего.\n",
    "- Попробуйте batch-нормализацию вместо дропаута. Строго говоря, batch-нормализация не является методом регуляризации, но никто не запрещает нам экспериментировать с ней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (❍ᴥ❍ʋ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишите результаты экспериментов (без их описания за работу ставится ноль баллов)\n",
    "\n",
    "__Ваше подробное описание:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 12 (1 балл).** Теперь, когда мы определились с выбором архитектуры нейронной сети, пора заняться рутиной DL-инженера &mdash; перебором гиперпараметров. Подберите оптимальное значение lr по значению RMSE на валидации (по логарифмической сетке, достаточно посмотреть 3-4 значения). Затем подберите оптимальное значение weight decay для данного lr (тоже по логарифмической сетке, типичные значения этого параметра лежат в диапазоне $[10^{-6}, 10^{-3}]$, но не забудьте включить нулевое значение в сетку). Постройте графики зависимости RMSE на трейне и на валидации от значений параметров. Прокомментируйте получившиеся зависимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (｡❤‿❤｡)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишите результаты экспериментов (без их описания за работу ставится ноль баллов)\n",
    "\n",
    "__Ваше подробное описание:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Как вы могли заметить, еще одна рутина DL-инженера &mdash; утомительное ожидание обучения моделей.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 13 (6 баллов).**\n",
    "\n",
    "Думаю направление размышлений вы поняли. Постарайтесь с помощью своих экспериментов выбить максимально возможное значение RMSE на тестовой выборке. Соотношение между полученным значением метрики на тестовой выборке и баллами за задание следующее:\n",
    "\n",
    "- $\\text{RMSE} \\le 8.90 $ &mdash; 2 балла\n",
    "- $\\text{RMSE} \\le 8.80 $ &mdash; 4 балла\n",
    "- $\\text{RMSE} \\le 8.75 $ &mdash; 6 баллов\n",
    "\n",
    "**Различные трюки, которые можно попробовать:**\n",
    "\n",
    "1. Попробуйте делать во время обучения раннюю остановку обучения и сохранять модель в тот момент, когда качество на валидации начало ухудшаься, то есть модель начала переобучаться\n",
    "2. Попробуйте усложнить архитектуру нейросет\n",
    "    - Больше/меньше нейронов\n",
    "    - Больше/меньше слоёв\n",
    "    - Другие функции активации (tanh, relu, leaky relu, elu etc)\n",
    "    - Регуляризация (dropout, l1,l2)\n",
    "3. Попробуйте другие оптимизаторы, а также смену скорости обучения по расписанию.\n",
    "\n",
    "И это далеко не полный список. Обратите внимание, что делать grid_search для больших сеток это довольно времязатратное занятие... Попробовать несколько значений, как мы делали в заданиях выше, адекватно, но делать какой-то огромный перебор будет самоубийством.\n",
    "\n",
    "Логгируйте свои эксперименты. За один прогон пробуйте одно изменение. Иначе будет непонятно какие именно изменения улучшили качество, а какие ухудшили. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# ༼ つ ಥ_ಥ ༽つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишите результаты экспериментов (без их описания за работу ставится ноль баллов)\n",
    "\n",
    "__Ваше подробное описание:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонус (0.1 балла)\n",
    "\n",
    "Прикрепите фотографию того, как вы начали этот сентябрь. Какую самую классную эмоцию вы испытали за прошедший месяц?\n",
    "\n",
    "__место для картики и эмоции__\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
